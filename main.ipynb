{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "import seaborn as sns\n",
    "from time import time\n",
    "from collections import OrderedDict\n",
    "from CBFV import composition\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import pickle\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import Ridge, LinearRegression\n",
    "from sklearn.ensemble import AdaBoostRegressor, GradientBoostingRegressor, ExtraTreesRegressor, RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, normalize, OrdinalEncoder\n",
    "from sklearn.model_selection import learning_curve, GridSearchCV, cross_validate, GroupKFold\n",
    "from sklearn.feature_selection import RFECV, RFE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNG_SEED = 8\n",
    "np.random.seed(RNG_SEED)\n",
    "DATA_PATH = os.path.join(os.getcwd(), 'Data')\n",
    "MODELS_PATH = os.path.join(os.getcwd(), 'Models')\n",
    "WEIGHTS_PATH = os.path.join(os.getcwd(), 'Weights')\n",
    "ASSETS_PATH = os.path.join(os.getcwd(), 'Assets')\n",
    "RESULTS_PATH = os.path.join(os.getcwd(), 'Results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(DATA_PATH + \"/intermetallics_train7.csv\")\n",
    "df_val = pd.read_csv(DATA_PATH + \"/intermetallics_val7.csv\")\n",
    "df_test = pd.read_csv(DATA_PATH + \"/intermetallics_test7.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train DataFrame shape: (5872, 1594)\n",
      "df_val DataFrame shape: (1722, 1594)\n",
      "df_test DataFrame shape: (844, 1594)\n"
     ]
    }
   ],
   "source": [
    "# remove categorical data and individual atomic fractions that I added  with matminer (except B)\n",
    "df_train.drop(columns=['composition', 'material_id',\n",
    "              'structure'], axis=1, inplace=True)\n",
    "\n",
    "df_val.drop(columns=['composition', 'material_id',\n",
    "            'structure'], axis=1, inplace=True)\n",
    "\n",
    "df_test.drop(columns=['composition', 'material_id',\n",
    "             'structure'], axis=1, inplace=True)\n",
    "\n",
    "# Gonna train  total_magnetization_ per formula unit so need to remove all other magnetic fields as to not overtrain the data\n",
    "df_train.drop(['total_magnetization',\n",
    "              'total_magnetization_normalized_vol'], axis=1, inplace=True)\n",
    "df_val.drop(['total_magnetization',\n",
    "            'total_magnetization_normalized_vol'], axis=1, inplace=True)\n",
    "df_test.drop(['total_magnetization',\n",
    "             'total_magnetization_normalized_vol'], axis=1, inplace=True)\n",
    "\n",
    "# save an example of the final traiing dataFrame, so that I can match the order of columns\n",
    "df_train.to_csv(os.path.join(\n",
    "    DATA_PATH, 'trainSet_columnOrder.csv'), index=False)\n",
    "\n",
    "print(f'df_train DataFrame shape: {df_train.shape}')\n",
    "print(f'df_val DataFrame shape: {df_val.shape}')\n",
    "print(f'df_test DataFrame shape: {df_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Input Data: 100%|██████████| 5872/5872 [00:00<00:00, 45639.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tFeaturizing Compositions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning Features...: 100%|██████████| 5872/5872 [00:00<00:00, 33811.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCreating Pandas Objects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Input Data: 100%|██████████| 1722/1722 [00:00<00:00, 53092.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tFeaturizing Compositions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning Features...: 100%|██████████| 1722/1722 [00:00<00:00, 33719.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCreating Pandas Objects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Input Data: 100%|██████████| 844/844 [00:00<00:00, 55486.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tFeaturizing Compositions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning Features...: 100%|██████████| 844/844 [00:00<00:00, 31004.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCreating Pandas Objects...\n"
     ]
    }
   ],
   "source": [
    "# Need to rename formula_pretty column to formula and total_magnetization_formula_units to target since CBFV needs that\n",
    "rename_dict = {'total_magnetization_normalized_formula_units': 'target'}\n",
    "df_train = df_train.rename(columns=rename_dict)\n",
    "df_val = df_val.rename(columns=rename_dict)\n",
    "df_test = df_test.rename(columns=rename_dict)\n",
    "\n",
    "X_train_unscaled, y_train, formulae_train, skipped_train = composition.generate_features(\n",
    "    df_train, elem_prop='magpie', drop_duplicates=False, extend_features=True, sum_feat=True)\n",
    "X_val_unscaled, y_val, formulae_val, skipped_val = composition.generate_features(\n",
    "    df_val, elem_prop='magpie', drop_duplicates=False, extend_features=True, sum_feat=True)\n",
    "X_test_unscaled, y_test, formulae_test, skipped_test = composition.generate_features(\n",
    "    df_test, elem_prop='magpie', drop_duplicates=False, extend_features=True, sum_feat=True)\n",
    "\n",
    "columns = X_train_unscaled.columns.values.tolist()\n",
    "\n",
    "\n",
    "# Scale and Normalize all the numerical training features\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train_unscaled)\n",
    "X_val = scaler.transform(X_val_unscaled)\n",
    "X_test = scaler.transform(X_test_unscaled)\n",
    "\n",
    "X_train = normalize(X_train)\n",
    "X_val = normalize(X_val)\n",
    "X_test = normalize(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7594, 1746)\n"
     ]
    }
   ],
   "source": [
    "# Define some helper functions\n",
    "def instantiate_model(model_name):\n",
    "    model = model_name()\n",
    "    return model\n",
    "\n",
    "\n",
    "def fit_model(model, X_train, y_train):\n",
    "    ti = time()\n",
    "    model = instantiate_model(model)\n",
    "    model.fit(X_train, y_train)\n",
    "    fit_time = time() - ti\n",
    "    return model, fit_time\n",
    "\n",
    "\n",
    "def evaluate_model(model, X, y_act):\n",
    "    y_pred = model.predict(X)\n",
    "    r2 = r2_score(y_act, y_pred)\n",
    "    mae = mean_absolute_error(y_act, y_pred)\n",
    "    rmse_val = mean_squared_error(y_act, y_pred, squared=False)\n",
    "    return r2, mae, rmse_val\n",
    "\n",
    "\n",
    "def fit_evaluate_model(model, model_name, X_train, y_train, X_val, y_act_val):\n",
    "    model, fit_time = fit_model(model, X_train, y_train)\n",
    "    r2_train, mae_train, rmse_train = evaluate_model(model, X_train, y_train)\n",
    "    r2_val, mae_val, rmse_val = evaluate_model(model, X_val, y_act_val)\n",
    "    result_dict = {\n",
    "        'model_name': model_name,\n",
    "        'model_name_pretty': type(model).__name__,\n",
    "        'model_params': model.get_params(),\n",
    "        'fit_time': fit_time,\n",
    "        'r2_train': r2_train,\n",
    "        'mae_train': mae_train,\n",
    "        'rmse_train': rmse_train,\n",
    "        'r2_val': r2_val,\n",
    "        'mae_val': mae_val,\n",
    "        'rmse_val': rmse_val}\n",
    "    return model, result_dict\n",
    "\n",
    "\n",
    "def append_result_df(df, result_dict):\n",
    "    df_result_appended = df.append(result_dict, ignore_index=True)\n",
    "    return df_result_appended\n",
    "\n",
    "\n",
    "def append_model_dict(dic, model_name, model):\n",
    "    dic[model_name] = model\n",
    "    return dic\n",
    "\n",
    "\n",
    "# Build an empty DataFrame to store model results:\n",
    "df_classics = pd.DataFrame(columns=['model_name',\n",
    "                                    'model_name_pretty',\n",
    "                                    'model_params',\n",
    "                                    'fit_time',\n",
    "                                    'r2_train',\n",
    "                                    'mae_train',\n",
    "                                    'rmse_train',\n",
    "                                    'r2_val',\n",
    "                                    'mae_val',\n",
    "                                    'rmse_val'])\n",
    "df_classics\n",
    "\n",
    "# Build a dictionary of model names\n",
    "classic_model_names = OrderedDict({\n",
    "    'dumr': DummyRegressor,\n",
    "    'rr': Ridge,\n",
    "    'abr': AdaBoostRegressor,\n",
    "    'gbr': GradientBoostingRegressor,\n",
    "    'rfr': RandomForestRegressor,\n",
    "    'etr': ExtraTreesRegressor,\n",
    "    'svr': SVR,\n",
    "    'lsvr': LinearSVR,\n",
    "    'knr': KNeighborsRegressor,\n",
    "})\n",
    "\n",
    "\n",
    "# Concatenate the train and validation datasets together\n",
    "X_train_new = np.concatenate((X_train, X_val), axis=0)\n",
    "y_train_new = pd.concat((y_train, y_val), axis=0)\n",
    "\n",
    "print(X_train_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using K-fold Cross validation to check for overfitting and get a better idea of the errors\n",
    "\n",
    "# formula group needs to be integers\n",
    "enc = OrdinalEncoder()\n",
    "\n",
    "df_train_new =pd.concat((df_train, df_val), axis=0)\n",
    "enc.fit(df_train_new[[\"formula\",\"number\"]])\n",
    "df_train_new[[\"formula\",\"number\"]] = enc.transform(df_train_new[[\"formula\",\"number\"]])\n",
    "\n",
    "groups = df_train_new['formula']\n",
    "gkf= GroupKFold(n_splits = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize data for CV\n",
    "rng = np.random.RandomState(1338)\n",
    "cmap_data = plt.cm.Paired\n",
    "cmap_cv = plt.cm.coolwarm\n",
    "\n",
    "\n",
    "def visualize_groups(classes, groups, name):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(\n",
    "        range(len(groups)),\n",
    "        [0.5] * len(groups),\n",
    "        c=groups,\n",
    "        marker=\"_\",\n",
    "        lw=50,\n",
    "        cmap=cmap_data,\n",
    "    )\n",
    "    ax.scatter(\n",
    "        range(len(groups)),\n",
    "        [3.5] * len(groups),\n",
    "        c=classes,\n",
    "        marker=\"_\",\n",
    "        lw=50,\n",
    "        cmap=cmap_data,\n",
    "    )\n",
    "    ax.set(\n",
    "        ylim=[-1, 5],\n",
    "        yticks=[0.5, 3.5],\n",
    "        yticklabels=[\"Data\\ngroup\", \"Data\\nclass\"],\n",
    "        xlabel=\"Sample index\",\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "\n",
    "data_vis = visualize_groups(y_train_new, groups, \"no groups\")\n",
    "\n",
    "os.path.join(ASSETS_PATH, 'jarvis', 'Data_vis_{}_transparent.png')\n",
    "data_vis.savefig(os.path.join(ASSETS_PATH, 'jarvis', 'Data_vis_{}_transparent.png'),\n",
    "                        bbox_inches='tight', dpi=600, transparent=True)\n",
    "\n",
    "data_vis.savefig(os.path.join(ASSETS_PATH, 'jarvis', 'Data_vis_{}_.png'),\n",
    "                        bbox_inches='tight', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_cv_indices(cv, X, y, group, ax, n_splits, lw=5):\n",
    "    \"\"\"Create a sample plot for indices of a cross-validation object.\"\"\"\n",
    "\n",
    "    # Generate the training/testing visualizations for each CV split\n",
    "    for ii, (tr, tt) in enumerate(cv.split(X=X, y=y, groups=group)):\n",
    "        # Fill in indices with the training/test groups\n",
    "        indices = np.array([np.nan] * len(X))\n",
    "        indices[tt] = 1\n",
    "        indices[tr] = 0\n",
    "\n",
    "        # Visualize the results\n",
    "        ax.scatter(\n",
    "            range(len(indices)),\n",
    "            [ii + 0.5] * len(indices),\n",
    "            c=indices,\n",
    "            marker=\"_\",\n",
    "            lw=lw,\n",
    "            cmap=cmap_cv,\n",
    "            vmin=-0.2,\n",
    "            vmax=1.2,\n",
    "        )\n",
    "\n",
    "    # Plot the data classes and groups at the end\n",
    "    ax.scatter(\n",
    "        range(len(X)), [ii + 1.5] * len(X), c=y, marker=\"_\", lw=lw, cmap=cmap_data\n",
    "    )\n",
    "\n",
    "    ax.scatter(\n",
    "        range(len(X)), [ii + 2.5] * len(X), c=group, marker=\"_\", lw=lw, cmap=cmap_data\n",
    "    )\n",
    "\n",
    "    # Formatting\n",
    "    yticklabels = list(range(n_splits)) + [\"class\", \"group\"]\n",
    "    ax.set(\n",
    "        yticks=np.arange(n_splits + 2) + 0.5,\n",
    "        yticklabels=yticklabels,\n",
    "        xlabel=\"Sample index\",\n",
    "        ylabel=\"CV iteration\",\n",
    "        ylim=[n_splits + 2.2, -0.2],\n",
    "        xlim=[0, 100],\n",
    "    )\n",
    "    ax.set_title(\"{}\".format(type(cv).__name__), fontsize=15)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting CV\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "cv = GroupKFold(n_splits=5)\n",
    "cv_plot = plot_cv_indices(gkf, df_train_new, y_train_new, groups, ax, 5)\n",
    "\n",
    "ax.legend(\n",
    "    [Patch(color=cmap_cv(0.8)), Patch(color=cmap_cv(0.02))],\n",
    "    [\"Testing set\", \"Training set\"],\n",
    "    loc=(1.02, 0.8),\n",
    ")\n",
    "cv_plot.figure.savefig(os.path.join(ASSETS_PATH, 'jarvis', 'cv_plot2_{}_transparent.png'), bbox_inches='tight', dpi=600, transparent=True)\n",
    "cv_plot.figure.savefig(os.path.join(ASSETS_PATH, 'jarvis', 'cv_plot2_{}_.png'), bbox_inches='tight', dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Trees Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new model to make CV fold plots\n",
    "etr_cv_model = ExtraTreesRegressor(n_estimators=100, criterion='squared_error',\n",
    "                                   max_features=1.0, verbose=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = {'r2': 'r2',\n",
    "           'rmse': 'neg_root_mean_squared_error'}\n",
    "\n",
    "ti = time()\n",
    "\n",
    "scores = cross_validate(etr_cv_model, X_train_new, y_train_new, groups=groups, verbose=4,\n",
    "                        scoring=scoring, cv=gkf, return_train_score=True)\n",
    "\n",
    "etr_cv_model.fit(X_train_new, y_train_new)\n",
    "dt = time() - ti\n",
    "\n",
    "print(f'Finished fitting model, total time: {dt:0.2f} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scores.keys())\n",
    "\n",
    "scores_mean = {'r2': np.mean(scores['test_r2']),\n",
    "               'rmse': np.mean(scores['test_rmse'])}\n",
    "\n",
    "test_r2 = {'0': scores['test_r2'][0], '1': scores['test_r2'][1], '2': scores['test_r2'][2],\n",
    "           '3': scores['test_r2'][3], '4': scores['test_r2'][4]}\n",
    "\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(range(len(test_r2.keys())),\n",
    "         test_r2.values(), linestyle='-', marker='o')\n",
    "plt.xticks(range(len(test_r2)), [str(key) for key in list(test_r2.keys())])\n",
    "plt.ylim(0.4, 1)\n",
    "plt.text(0, .6, 'mean $r^2$ = {:0.3f}'.format(scores_mean['r2']), fontsize=20,\n",
    "         bbox=dict(facecolor='red', alpha=0.3))\n",
    "\n",
    "plt.xlabel('Cross validation folds')\n",
    "plt.ylabel('$r^2$')\n",
    "plt.title('$r^2$ across cross validation folds')\n",
    "\n",
    "r2_cv = plt.gcf()\n",
    "r2_cv.savefig(os.path.join(ASSETS_PATH, 'jarvis', 'r2_5-fold_cv_{}_transparent.png'),\n",
    "              bbox_inches='tight', dpi=600, transparent=True)\n",
    "r2_cv.savefig(os.path.join(ASSETS_PATH, 'jarvis', 'r2_5-fold_cv_{}_.png'),\n",
    "              bbox_inches='tight', dpi=600)\n",
    "\n",
    "\n",
    "test_rmse = {'0': np.negative(scores['test_rmse'][0]), '1': np.negative(scores['test_rmse'])[1],\n",
    "             '2': np.negative(scores['test_rmse'][2]), '3': np.negative(scores['test_rmse'][3]),\n",
    "             '4': np.negative(scores['test_rmse'])[4]}\n",
    "\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(range(len(test_rmse.keys())), test_rmse.values(),\n",
    "         linestyle='-', marker='o', color='green')\n",
    "plt.xticks(range(len(test_rmse)), [str(key) for key in list(test_rmse.keys())])\n",
    "plt.ylim(2, 3.5)\n",
    "plt.text(2.5, 2.5, 'mean RMSE = {:0.3f}'.format(np.negative(scores_mean['rmse'])), fontsize=20,\n",
    "         bbox=dict(facecolor='red', alpha=0.3))\n",
    "\n",
    "plt.xlabel('Cross validation folds')\n",
    "plt.ylabel('RMSE ($\\u03bc_B$/ f.u.)')\n",
    "plt.title('RMSE across cross validation folds')\n",
    "\n",
    "rmse_cv = plt.gcf()\n",
    "\n",
    "rmse_cv.savefig(os.path.join(ASSETS_PATH, 'jarvis', 'rmse_5-fold_cv_{}_transparent.png'),\n",
    "                bbox_inches='tight', dpi=600, transparent=True)\n",
    "rmse_cv.savefig(os.path.join(ASSETS_PATH, 'jarvis', 'rmse_5-fold_cv_{}_.png'),\n",
    "                bbox_inches='tight', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes = [762, 1525, 2287, 3049, 3811, 4573, 5335, 6097, 6859, 7627]\n",
    "\n",
    "ti = time()\n",
    "train_sizes, train_scores, validation_scores = learning_curve(etr_cv_model, X_train_new, y_train_new, groups=groups, scoring='r2',cv=gkf, shuffle=True, random_state=RNG_SEED)\n",
    "dt = time() - ti\n",
    "\n",
    "# Plotting learning curve\n",
    "train_scores_mean = train_scores.mean(axis=1)\n",
    "train_scores_std = train_scores.std(axis=1)\n",
    "\n",
    "\n",
    "val_scores_mean = validation_scores.mean(axis=1)\n",
    "val_scores_std = validation_scores.std(axis=1)\n",
    "print('Mean training scores\\n\\n', pd.Series(\n",
    "    train_scores_mean, index=train_sizes))\n",
    "print('\\n', '-' * 20)  # separator\n",
    "print('\\nMean validation scores\\n\\n', pd.Series(\n",
    "    val_scores_mean, index=train_sizes))\n",
    "\n",
    "\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(train_sizes, train_scores_mean, label='Training $r^2$')\n",
    "plt.plot(train_sizes, val_scores_mean, label='Validation $r^2$')\n",
    "plt.ylabel('r2 score', fontsize=15)\n",
    "plt.xlabel('Training set size', fontsize=14)\n",
    "plt.title('Learning curves for a linear regression model', fontsize=18, y=1.03)\n",
    "plt.legend()\n",
    "# plt.ylim(0,4)\n",
    "\n",
    "# plt.text(5.5,5,'gap = {:0.3f}'.format(np.negative.difference(train(validation_scores_mean[4])),\n",
    "#                                    train_scores_mean[4]), fontsize = 20,\n",
    "#         bbox = dict(facecolor = 'red', alpha = 0.3))\n",
    "\n",
    "learn_curve = plt.gcf()\n",
    "learn_curve.savefig(os.path.join(ASSETS_PATH, 'jarvis', 'learn_curve_{}_transparent.png'), bbox_inches='tight', dpi=600, transparent=True)\n",
    "learn_curve.savefig(os.path.join(ASSETS_PATH, 'jarvis', 'learn_curve_{}_.png'),bbox_inches='tight', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning and CV\n",
    "\n",
    "# Set up hyperparameter tuning grid to be implemented into CV\n",
    "scoring = {'r2': 'r2',\n",
    "           'rmse': 'neg_root_mean_squared_error'}\n",
    "\n",
    "\n",
    "params_etr = {'n_estimators': [50, 1000], 'max_depth': [50, 100, 1000], 'min_samples_leaf': [\n",
    "    100, 0.1], 'min_samples_split': [100, 0.1], 'max_features': [1.0, 0.75]}\n",
    "\n",
    "\n",
    "ti = time()\n",
    "etr_model = ExtraTreesRegressor(criterion='squared_error')\n",
    "gs_etr = GridSearchCV(estimator=etr_model, param_grid=params_etr, verbose=4,\n",
    "                      scoring='neg_root_mean_squared_error', cv=gkf, return_train_score=True, refit=True)\n",
    "\n",
    "dt = time() - ti\n",
    "print(f'Finished grid search, total time: {dt:0.2f} s')\n",
    "\n",
    "\n",
    "ti = time()\n",
    "gs_etr.fit(X_train_new, y_train_new, groups=groups)\n",
    "dt = time() - ti\n",
    "\n",
    "print(f'Finished fitting grid search model, total time: {dt:0.2f} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert results into a DataFrame\n",
    "gs_results1 = pd.DataFrame(gs_etr.cv_results_)[\n",
    "    ['params', 'mean_test_score', 'mean_train_score', 'rank_test_score', 'mean_train_score']]\n",
    "# sort by test scores\n",
    "gs_results1.sort_values('rank_test_score')\n",
    "\n",
    "bestIndex = gs_etr.best_index_\n",
    "mean_rmse_score1 = np.negative(gs_etr.best_score_)\n",
    "\n",
    "# gs_results1.to_csv(r'C:\\Users\\joeya\\Documents\\Fokwa Group\\ML_tutorial\\intermetallics\\tables&lists\\magpie\\gs_results1.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second Hyperparameter tuning and CV\n",
    "\n",
    "# Set up hyperparameter tuning grid to be implemented into CV\n",
    "scoring = {'r2': 'r2',\n",
    "           'rmse': 'neg_root_mean_squared_error'}\n",
    "\n",
    "\n",
    "# Try with n_estimators = 50 to reduce computational cost and the change it to 1000 in next gs step\n",
    "params_etr = {'n_estimators': [50], 'min_samples_leaf': [\n",
    "    1, 25, 50, 100, 200], 'min_samples_split': [2, 25, 50, 100, 200], 'max_features': [1.0]}\n",
    "\n",
    "\n",
    "ti = time()\n",
    "etr_model = ExtraTreesRegressor(criterion='squared_error')\n",
    "gs_etr = GridSearchCV(estimator=etr_model, param_grid=params_etr, verbose=4,\n",
    "                      scoring='neg_root_mean_squared_error', cv=gkf, return_train_score=True, refit=True)\n",
    "\n",
    "dt = time() - ti\n",
    "print(f'Finished grid search, total time: {dt:0.2f} s')\n",
    "\n",
    "\n",
    "ti = time()\n",
    "gs_etr.fit(X_train_new, y_train_new, groups=groups)\n",
    "dt = time() - ti\n",
    "\n",
    "print(f'Finished fitting grid search model, total time: {dt:0.2f} s')\n",
    "\n",
    "# Convert results into a DataFrame\n",
    "gs_results2 = pd.DataFrame(gs_etr.cv_results_)[\n",
    "    ['params', 'mean_test_score', 'mean_train_score', 'rank_test_score', 'mean_train_score']]\n",
    "# sort by test scores\n",
    "gs_results2.sort_values('rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_rmse_score2 = np.negative(gs_etr.best_score_)\n",
    "# gs_results2.to_csv(r'C:\\Users\\joeya\\Documents\\Fokwa Group\\ML_tutorial\\intermetallics\\tables&lists\\magpie\\gs_results2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3rd Hyperparameter tuning and CV\n",
    "\n",
    "# Set up hyperparameter tuning grid to be implemented into CV\n",
    "scoring = {'r2': 'r2',\n",
    "           'rmse': 'neg_root_mean_squared_error'}\n",
    "\n",
    "# Try with n_estimators = 50 to reduce computational cost and the change it to 1000 in next gs step\n",
    "params_etr = {'n_estimators': [50], 'min_samples_leaf': [1, 2], 'min_samples_split': [\n",
    "    2, 3, 4, 5, 6, 7, 9, 10, 15, 20], 'max_features': [1.0]}\n",
    "\n",
    "\n",
    "ti = time()\n",
    "etr_model = ExtraTreesRegressor(criterion='squared_error')\n",
    "gs_etr = GridSearchCV(estimator=etr_model, param_grid=params_etr, verbose=4,\n",
    "                      scoring='neg_root_mean_squared_error', cv=gkf, return_train_score=True, refit=True)\n",
    "\n",
    "dt = time() - ti\n",
    "print(f'Finished grid search, total time: {dt:0.2f} s')\n",
    "\n",
    "\n",
    "ti = time()\n",
    "gs_etr.fit(X_train_new, y_train_new, groups=groups)\n",
    "dt = time() - ti\n",
    "\n",
    "print(f'Finished fitting grid search model, total time: {dt:0.2f} s')\n",
    "\n",
    "# Convert results into a DataFrame\n",
    "gs_results3 = pd.DataFrame(gs_etr.cv_results_)[\n",
    "    ['params', 'mean_test_score', 'mean_train_score', 'rank_test_score', 'mean_train_score']]\n",
    "# sort by test scores\n",
    "gs_results3.sort_values('rank_test_score')\n",
    "\n",
    "mean_rmse_score = np.negative(gs_etr.best_score_)\n",
    "# gs_results3.to_csv(r'C:\\Users\\joeya\\Documents\\Fokwa Group\\ML_tutorial\\intermetallics\\tables&lists\\magpie\\gs_results3.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4th Hyperparameter tuning and CV\n",
    "\n",
    "# Set up hyperparameter tuning grid to be implemented into CV\n",
    "scoring = {'r2': 'r2',\n",
    "           'rmse': 'neg_root_mean_squared_error'}\n",
    "\n",
    "# Try with n_estimators = 50 to reduce computational cost and the change it to 1000 in next gs step\n",
    "params_etr = {'n_estimators': [50], 'min_samples_leaf': [1, 2], 'min_samples_split': [\n",
    "    10, 20, 30, 40, 50, 60, 70, 80, 90, 100], 'max_features': [1.0]}\n",
    "\n",
    "\n",
    "ti = time()\n",
    "etr_model = ExtraTreesRegressor(criterion='squared_error')\n",
    "gs_etr = GridSearchCV(estimator=etr_model, param_grid=params_etr, verbose=4,\n",
    "                      scoring='neg_root_mean_squared_error', cv=gkf, return_train_score=True, refit=True)\n",
    "\n",
    "dt = time() - ti\n",
    "print(f'Finished grid search, total time: {dt:0.2f} s')\n",
    "\n",
    "\n",
    "ti = time()\n",
    "gs_etr.fit(X_train_new, y_train_new, groups=groups)\n",
    "dt = time() - ti\n",
    "\n",
    "print(f'Finished fitting grid search model, total time: {dt:0.2f} s')\n",
    "\n",
    "# Convert results into a DataFrame\n",
    "gs_results4 = pd.DataFrame(gs_etr.cv_results_)[\n",
    "    ['params', 'mean_test_score', 'mean_train_score', 'rank_test_score', 'mean_train_score']]\n",
    "# sort by test scores\n",
    "gs_results4.sort_values('rank_test_score')\n",
    "\n",
    "mean_rmse_score = np.negative(gs_etr.best_score_)\n",
    "\n",
    "gs_results4.to_csv(os.path.join(RESULTS_PATH, 'jarvis',\n",
    "                   'Set7', 'gs_results4.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For iteration number 5, optimal min_samples_leaf could be around min_samples_split/3\n",
    "\n",
    "# Set up hyperparameter tuning grid to be implemented into CV\n",
    "scoring = {'r2': 'r2',\n",
    "           'rmse': 'neg_root_mean_squared_error'}\n",
    "\n",
    "# Try with n_estimators = 50 to reduce computational cost and the change it to 1000 in next gs step\n",
    "params_etr = {'n_estimators': [50], 'min_samples_leaf': [\n",
    "    10, 20, 30], 'min_samples_split': [10, 20, 30, 40, 50, 60], 'max_features': [1.0]}\n",
    "\n",
    "\n",
    "ti = time()\n",
    "etr_model = ExtraTreesRegressor(criterion='squared_error')\n",
    "gs_etr = GridSearchCV(estimator=etr_model, param_grid=params_etr, verbose=4,\n",
    "                      scoring='neg_root_mean_squared_error', cv=gkf, return_train_score=True, refit=True)\n",
    "\n",
    "dt = time() - ti\n",
    "print(f'Finished grid search, total time: {dt:0.2f} s')\n",
    "\n",
    "\n",
    "ti = time()\n",
    "gs_etr.fit(X_train_new, y_train_new, groups=groups)\n",
    "dt = time() - ti\n",
    "\n",
    "print(f'Finished fitting grid search model, total time: {dt:0.2f} s')\n",
    "\n",
    "# Convert results into a DataFrame\n",
    "gs_results5 = pd.DataFrame(gs_etr.cv_results_)[\n",
    "    ['params', 'mean_test_score', 'mean_train_score', 'rank_test_score', 'mean_train_score']]\n",
    "# sort by test scores\n",
    "gs_results5.sort_values('rank_test_score')\n",
    "\n",
    "mean_rmse_score = np.negative(gs_etr.best_score_)\n",
    "gs_results5.to_csv(os.path.join(RESULTS_PATH, 'jarvis',\n",
    "                   'Set7', 'gs_results5.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For iteration number 6, Tuning optimal # of min_samples_leaf with min_samples_split = 40\n",
    "\n",
    "# Set up hyperparameter tuning grid to be implemented into CV\n",
    "scoring = {'r2': 'r2',\n",
    "           'rmse': 'neg_root_mean_squared_error'}\n",
    "\n",
    "# Try with n_estimators = 50 to reduce computational cost and the change it to 1000 in next gs step\n",
    "params_etr = {'n_estimators': [50], 'min_samples_leaf': [5, 8, 10, 11, 12, 13, 15,\n",
    "                                                         16, 17, 18, 19, 20, 23, 25], 'min_samples_split': [40], 'max_features': [1.0], }\n",
    "\n",
    "\n",
    "ti = time()\n",
    "etr_model = ExtraTreesRegressor(criterion='squared_error')\n",
    "gs_etr = GridSearchCV(estimator=etr_model, param_grid=params_etr, verbose=4,\n",
    "                      scoring='neg_root_mean_squared_error', cv=gkf, return_train_score=True, refit=True)\n",
    "\n",
    "dt = time() - ti\n",
    "print(f'Finished grid search, total time: {dt:0.2f} s')\n",
    "\n",
    "\n",
    "ti = time()\n",
    "gs_etr.fit(X_train_new, y_train_new, groups=groups)\n",
    "dt = time() - ti\n",
    "\n",
    "print(f'Finished fitting grid search model, total time: {dt:0.2f} s')\n",
    "\n",
    "# Convert results into a DataFrame\n",
    "gs_results6 = pd.DataFrame(gs_etr.cv_results_)[\n",
    "    ['params', 'mean_test_score', 'mean_train_score', 'rank_test_score', 'mean_train_score']]\n",
    "# sort by test scores\n",
    "gs_results6.sort_values('rank_test_score')\n",
    "\n",
    "mean_rmse_score = np.negative(gs_etr.best_score_)\n",
    "gs_results6.to_csv(os.path.join(RESULTS_PATH, 'jarvis',\n",
    "                   'Set7', 'gs_results6.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For iteration number 7 tuning min_weight_fraction_leaf\n",
    "\n",
    "# Set up hyperparameter tuning grid to be implemented into CV\n",
    "scoring = {'r2': 'r2',\n",
    "           'rmse': 'neg_root_mean_squared_error'}\n",
    "\n",
    "# Try with n_estimators = 50 to reduce computational cost and the change it to 1000 in next gs step\n",
    "params_etr = {'n_estimators': [50], 'min_samples_leaf': [13], 'min_weight_fraction_leaf': [\n",
    "    0.0, 0.25, 0.5, 0.75, 1.0], 'min_samples_split': [40], 'max_features': [1.0], }\n",
    "\n",
    "\n",
    "ti = time()\n",
    "etr_model = ExtraTreesRegressor(criterion='squared_error')\n",
    "gs_etr = GridSearchCV(estimator=etr_model, param_grid=params_etr, verbose=4,\n",
    "                      scoring='neg_root_mean_squared_error', cv=gkf, return_train_score=True, refit=True)\n",
    "\n",
    "dt = time() - ti\n",
    "print(f'Finished grid search, total time: {dt:0.2f} s')\n",
    "\n",
    "\n",
    "ti = time()\n",
    "gs_etr.fit(X_train_new, y_train_new, groups=groups)\n",
    "dt = time() - ti\n",
    "\n",
    "print(f'Finished fitting grid search model, total time: {dt:0.2f} s')\n",
    "\n",
    "# Convert results into a DataFrame\n",
    "gs_results7 = pd.DataFrame(gs_etr.cv_results_)[\n",
    "    ['params', 'mean_test_score', 'mean_train_score', 'rank_test_score', 'mean_train_score']]\n",
    "# sort by test scores\n",
    "gs_results7.sort_values('rank_test_score')\n",
    "\n",
    "mean_rmse_score = np.negative(gs_etr.best_score_)\n",
    "\n",
    "gs_results7.to_csv(os.path.join(RESULTS_PATH, 'jarvis',\n",
    "                   'Set7', 'gs_results7.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For iteration number 8 tuning max_features\n",
    "\n",
    "# Set up hyperparameter tuning grid to be implemented into CV\n",
    "scoring = {'r2': 'r2',\n",
    "           'rmse': 'neg_root_mean_squared_error'}\n",
    "\n",
    "# Try with n_estimators = 50 to reduce computational cost and the change it to 1000 in next gs step\n",
    "params_etr = {'n_estimators': [50], 'min_samples_leaf': [13], 'min_impurity_decrease': [\n",
    "    0.0, 0.25, 0.5, 0.75, 1.0], 'min_samples_split': [40], 'max_features': [1.0, 'sqrt', 'log2', 0.8, 0.5, 0.3], }\n",
    "\n",
    "\n",
    "ti = time()\n",
    "etr_model = ExtraTreesRegressor(\n",
    "    criterion='squared_error', random_state=RNG_SEED)\n",
    "gs_etr = GridSearchCV(estimator=etr_model, param_grid=params_etr, verbose=4,\n",
    "                      scoring='neg_root_mean_squared_error', cv=gkf, return_train_score=True, refit=True)\n",
    "\n",
    "dt = time() - ti\n",
    "print(f'Finished grid search, total time: {dt:0.2f} s')\n",
    "\n",
    "\n",
    "ti = time()\n",
    "gs_etr.fit(X_train_new, y_train_new, groups=groups)\n",
    "dt = time() - ti\n",
    "\n",
    "print(f'Finished fitting grid search model, total time: {dt:0.2f} s')\n",
    "\n",
    "# Convert results into a DataFrame\n",
    "gs_results8 = pd.DataFrame(gs_etr.cv_results_)[\n",
    "    ['params', 'mean_test_score', 'mean_train_score', 'rank_test_score', 'mean_train_score']]\n",
    "# sort by test scores\n",
    "gs_results8.sort_values('rank_test_score')\n",
    "\n",
    "mean_rmse_score = np.negative(gs_etr.best_score_)\n",
    "\n",
    "gs_results8.to_csv(os.path.join(RESULTS_PATH, 'jarvis',\n",
    "                   'Set7', 'gs_results8.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For iteration number 9 tuning max_features and N_estimators\n",
    "\n",
    "# Set up hyperparameter tuning grid to be implemented into CV\n",
    "scoring = {'r2': 'r2',\n",
    "           'rmse': 'neg_root_mean_squared_error'}\n",
    "\n",
    "# Try with n_estimators = 50 to reduce computational cost and the change it to 1000 in next gs step\n",
    "params_etr = {'n_estimators': [50, 100, 500, 1000], 'min_samples_leaf': [\n",
    "    13], 'min_samples_split': [40], 'max_features': [1.0, 0.8, 0.5, 0.3], }\n",
    "\n",
    "\n",
    "ti = time()\n",
    "etr_model = ExtraTreesRegressor(\n",
    "    criterion='squared_error', random_state=RNG_SEED)\n",
    "gs_etr = GridSearchCV(estimator=etr_model, param_grid=params_etr, verbose=4,\n",
    "                      scoring='neg_root_mean_squared_error', cv=gkf, return_train_score=True, refit=True)\n",
    "\n",
    "dt = time() - ti\n",
    "print(f'Finished grid search, total time: {dt:0.2f} s')\n",
    "\n",
    "\n",
    "ti = time()\n",
    "gs_etr.fit(X_train_new, y_train_new, groups=groups)\n",
    "dt = time() - ti\n",
    "\n",
    "print(f'Finished fitting grid search model, total time: {dt:0.2f} s')\n",
    "\n",
    "# Convert results into a DataFrame\n",
    "gs_results9 = pd.DataFrame(gs_etr.cv_results_)[\n",
    "    ['params', 'mean_test_score', 'mean_train_score', 'rank_test_score', 'mean_train_score']]\n",
    "# sort by test scores\n",
    "gs_results9.sort_values('rank_test_score')\n",
    "\n",
    "mean_rmse_score = np.negative(gs_etr.best_score_)\n",
    "\n",
    "gs_results9.to_csv(os.path.join(RESULTS_PATH, 'jarvis',\n",
    "                   'Set7', 'gs_results9.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For iteration number 10 tuning the nodes and splits again\n",
    "\n",
    "# Set up hyperparameter tuning grid to be implemented into CV\n",
    "scoring = {'r2': 'r2',\n",
    "           'rmse': 'neg_root_mean_squared_error'}\n",
    "\n",
    "#Try with n_estimators = 50 to reduce computational cost and the change it to 1000 in next gs step\n",
    "params_etr = {'n_estimators':[50], 'min_samples_leaf':[3,4,5,6,7,8,9,10,11,12,13]\n",
    "               , 'min_samples_split': [5 ,10, 20, 30], 'max_features':[1.0]}\n",
    "\n",
    "\n",
    "ti = time()\n",
    "etr_model = ExtraTreesRegressor(criterion='squared_error', random_state=RNG_SEED)\n",
    "gs_etr = GridSearchCV(estimator=etr_model, param_grid=params_etr,verbose=4,\n",
    "                    scoring = 'neg_root_mean_squared_error', cv = gkf, return_train_score=True, refit=True)\n",
    "\n",
    "dt = time() - ti\n",
    "print(f'Finished grid search, total time: {dt:0.2f} s')\n",
    "\n",
    "\n",
    "ti = time()\n",
    "gs_etr.fit(X_train_new, y_train_new,groups=groups)\n",
    "dt = time() - ti\n",
    "\n",
    "print(f'Finished fitting grid search model, total time: {dt:0.2f} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert results into a DataFrame\n",
    "gs_results10 = pd.DataFrame(gs_etr.cv_results_)[\n",
    "    ['params', 'mean_test_score', 'mean_train_score', 'rank_test_score', 'mean_train_score']]\n",
    "# sort by test scores\n",
    "gs_results10.sort_values('rank_test_score')\n",
    "\n",
    "mean_rmse_score = np.negative(gs_etr.best_score_)\n",
    "\n",
    "gs_results10.to_csv(os.path.join(RESULTS_PATH, 'jarvis',\n",
    "                    'Set7', 'gs_results10.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check  model learning curve right now\n",
    "train_sizes = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "\n",
    "etr_model2 = ExtraTreesRegressor(n_estimators=1000, criterion='squared_error',\n",
    "                                 min_samples_split=10, min_samples_leaf=5, max_features=1.0, verbose=4)\n",
    "\n",
    "ti = time()\n",
    "train_sizes, train_scores, validation_scores = learning_curve(etr_model2, X_train_new, y_train_new,\n",
    "                                                              groups=groups, scoring='r2',\n",
    "                                                              cv=gkf,\n",
    "                                                              shuffle=True, random_state=RNG_SEED)\n",
    "dt = time() - ti\n",
    "\n",
    "# Plotting learning curve\n",
    "\n",
    "UNTRIMMED_learn_curve_scores = pd.DataFrame()\n",
    "\n",
    "UNTRIMMED_learn_curve_scores['train_sizes'] = train_sizes\n",
    "UNTRIMMED_learn_curve_scores['train_r2'] = train_scores.mean(axis=1)\n",
    "UNTRIMMED_learn_curve_scores['validaton_r2'] = validation_scores.mean(axis=1)\n",
    "UNTRIMMED_learn_curve_scores.to_csv(RESULTS_PATH + '/jarvis/UNTRIMMED_learnCurve_rawData.csv', index=False)\n",
    "\n",
    "train_scores_mean = train_scores.mean(axis=1)\n",
    "train_scores_std = train_scores.std(axis=1)\n",
    "\n",
    "val_scores_mean = validation_scores.mean(axis=1)\n",
    "val_scores_std = validation_scores.std(axis=1)\n",
    "print('Mean training scores\\n\\n', pd.Series(\n",
    "    train_scores_mean, index=train_sizes))\n",
    "print('\\n', '-' * 20)  # separator\n",
    "print('\\nMean validation scores\\n\\n', pd.Series(\n",
    "    val_scores_mean, index=train_sizes))\n",
    "\n",
    "\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(train_sizes, train_scores_mean, label='Training error')\n",
    "plt.plot(train_sizes, val_scores_mean, label='Validation error')\n",
    "plt.ylabel('r2 score', fontsize=15)\n",
    "plt.xlabel('Training set size', fontsize=14)\n",
    "plt.title('Learning curves for a linear regression model', fontsize=18, y=1.03)\n",
    "plt.legend()\n",
    "# plt.ylim(0,4)\n",
    "\n",
    "# plt.text(5.5,5,'gap = {:0.3f}'.format(np.negative.difference(train(validation_scores_mean[4])),\n",
    "#                                    train_scores_mean[4]), fontsize = 20,\n",
    "#         bbox = dict(facecolor = 'red', alpha = 0.3))\n",
    "\n",
    "learn_curve = plt.gcf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check  model learning curve Before feature trimming\n",
    "train_sizes = np.linspace(0.1, 1.0, 10)\n",
    "\n",
    "etr_model2 = ExtraTreesRegressor(n_estimators=1000, criterion='squared_error',\n",
    "                                 min_samples_split=10, min_samples_leaf=5, max_features=1.0, verbose=4)\n",
    "\n",
    "ti = time()\n",
    "train_sizes, train_scores, validation_scores = learning_curve(etr_model2, X_train_new, y_train_new,\n",
    "                                                              groups=groups, scoring='r2',\n",
    "                                                              cv=gkf,\n",
    "                                                              shuffle=True, random_state=RNG_SEED)\n",
    "dt = time() - ti\n",
    "\n",
    "# Plotting learning curve\n",
    "\n",
    "UNTRIMMED_learn_curve_scores = pd.DataFrame()\n",
    "\n",
    "UNTRIMMED_learn_curve_scores['train_sizes'] = train_sizes\n",
    "UNTRIMMED_learn_curve_scores['train_r2'] = train_scores.mean(axis=1)\n",
    "UNTRIMMED_learn_curve_scores['validaton_r2'] = validation_scores.mean(axis=1)\n",
    "UNTRIMMED_learn_curve_scores.to_csv(os.path.join(\n",
    "    RESULTS_PATH, 'jarvis', 'UNTRIMMED_learnCurve_rawData.csv'), index=False)\n",
    "\n",
    "\n",
    "train_scores_mean = train_scores.mean(axis=1)\n",
    "train_scores_std = train_scores.std(axis=1)\n",
    "\n",
    "val_scores_mean = validation_scores.mean(axis=1)\n",
    "val_scores_std = validation_scores.std(axis=1)\n",
    "print('Mean training scores\\n\\n', pd.Series(\n",
    "    train_scores_mean, index=train_sizes))\n",
    "print('\\n', '-' * 20)  # separator\n",
    "print('\\nMean validation scores\\n\\n', pd.Series(\n",
    "    val_scores_mean, index=train_sizes))\n",
    "\n",
    "\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(train_sizes, train_scores_mean, label='Training error')\n",
    "plt.plot(train_sizes, val_scores_mean, label='Validation error')\n",
    "plt.ylabel('r2 score', fontsize=15)\n",
    "plt.xlabel('Training set size', fontsize=14)\n",
    "plt.title('Learning curves for a linear regression model', fontsize=18, y=1.03)\n",
    "plt.legend()\n",
    "# plt.ylim(0,4)\n",
    "\n",
    "# plt.text(5.5,5,'gap = {:0.3f}'.format(np.negative.difference(train(validation_scores_mean[4])),\n",
    "#                                    train_scores_mean[4]), fontsize = 20,\n",
    "#         bbox = dict(facecolor = 'red', alpha = 0.3))\n",
    "\n",
    "learn_curve = plt.gcf()\n",
    "learn_curve.savefig(os.path.join(ASSETS_PATH, 'jarvis', 'learn_curve2_{}_transparent.png'),bbox_inches='tight', dpi=600, transparent=True)\n",
    "learn_curve.savefig(os.path.join(ASSETS_PATH, 'jarvis', 'learn_curve2_{}_.png'),\n",
    "bbox_inches='tight', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new model after hyperparameter tuning to make CV fold plots\n",
    "etr_cv_model = ExtraTreesRegressor(n_estimators=1000, criterion='squared_error',\n",
    "                                   min_samples_split=10, min_samples_leaf=5, max_features=1.0, verbose=4)\n",
    "\n",
    "scoring = {'r2': 'r2',\n",
    "           'rmse': 'neg_root_mean_squared_error'}\n",
    "\n",
    "ti = time()\n",
    "\n",
    "scores = cross_validate(etr_cv_model, X_train_new, y_train_new, groups=groups, verbose=4,\n",
    "                        scoring=scoring, cv=gkf, return_train_score=True)\n",
    "\n",
    "etr_cv_model.fit(X_train_new, y_train_new)\n",
    "dt = time() - ti\n",
    "\n",
    "print(f'Finished fitting model, total time: {dt:0.2f} s')\n",
    "\n",
    "print(scores.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scores['test_r2'])\n",
    "UNTRIMMED_train_scores = pd.DataFrame()\n",
    "UNTRIMMED_train_scores['test_r2'] = scores['test_r2']\n",
    "# UNTRIMMED_train_scores_r2.to_csv('C:/Users/joeya/Documents/Fokwa Group/ML_tutorial/Intermetallics/tables&lists/jarvis/UNTRIMMED_test_r2.csv', index=True)\n",
    "\n",
    "scores_mean = {'r2': np.mean(scores['test_r2']),\n",
    "               'rmse': np.mean(scores['test_rmse'])}\n",
    "\n",
    "test_r2 = {'0': scores['test_r2'][0], '1': scores['test_r2'][1], '2': scores['test_r2'][2],\n",
    "           '3': scores['test_r2'][3], '4': scores['test_r2'][4]}\n",
    "\n",
    "plt.rcParams.update({'font.size': 25})\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(range(len(test_r2.keys())),\n",
    "         test_r2.values(), linestyle='-', marker='o')\n",
    "plt.xticks(range(len(test_r2)), [str(key) for key in list(test_r2.keys())])\n",
    "plt.ylim(0.7, 1)\n",
    "plt.text(0, 0.75, 'mean $r^2$ = {:0.3f}'.format(scores_mean['r2']), fontsize=25,\n",
    "         bbox=dict(facecolor='red', alpha=0.3))\n",
    "\n",
    "plt.xlabel('Cross validation folds')\n",
    "plt.ylabel('$r^2$ (arb. units)')\n",
    "plt.title('$r^2$ across cross validation folds')\n",
    "\n",
    "\n",
    "r2_cv = plt.gcf()\n",
    "r2_cv.savefig(os.path.join(ASSETS_PATH, 'jarvis', 'Set7',\n",
    "                           'tunedModel_UNTRIMMED_r2_5-fold_cv_{}_transparent.png'), bbox_inches='tight', dpi=600, transparent=True)\n",
    "r2_cv.savefig(os.path.join(ASSETS_PATH, 'jarvis', 'Set7', 'tunedModel_UNTRIMMED_r2_5-fold_cv_{}_.png'),\n",
    "              bbox_inches='tight', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rmse = {'0': np.negative(scores['test_rmse'][0]), '1': np.negative(scores['test_rmse'])[1],\n",
    "             '2': np.negative(scores['test_rmse'][2]), '3': np.negative(scores['test_rmse'][3]),\n",
    "             '4': np.negative(scores['test_rmse'])[4]}\n",
    "\n",
    "UNTRIMMED_train_scores['test_rmse'] = scores['test_rmse']\n",
    "\n",
    "plt.rcParams.update({'font.size': 25})\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(range(len(test_rmse.keys())), test_rmse.values(),\n",
    "         linestyle='-', marker='o', color='green')\n",
    "plt.xticks(range(len(test_rmse)), [str(key) for key in list(test_rmse.keys())])\n",
    "plt.ylim(1, 5)\n",
    "plt.text(0, 2.0, 'mean RMSE = {:0.3f}'.format(np.negative(scores_mean['rmse'])), fontsize=25,\n",
    "         bbox=dict(facecolor='red', alpha=0.3))\n",
    "\n",
    "plt.xlabel('Cross validation folds')\n",
    "plt.ylabel('RMSE ($\\u03bc_B$/ f.u.)', fontsize=25)\n",
    "plt.title('RMSE across cross validation folds')\n",
    "\n",
    "\n",
    "rmse_cv = plt.gcf()\n",
    "rmse_cv.savefig(os.path.join(ASSETS_PATH, 'jarvis', 'Set7',\n",
    "                             'tunedModel_UNTRIMMED_rmse_5-fold_cv_{}_transparent.png'),\n",
    "                bbox_inches='tight', dpi=600, transparent=True)\n",
    "rmse_cv.savefig(os.path.join(ASSETS_PATH, 'jarvis', 'Set7',\n",
    "                             'tunedModel_UNTRIMMED_rmse_5-fold_cv_{}_.png'),\n",
    "                bbox_inches='tight', dpi=600)\n",
    "\n",
    "UNTRIMMED_train_scores.to_csv(os.path.join(RESULTS_PATH, 'jarvis', 'Set7',\n",
    "                                           'UNTRIMMED_test_rawData.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the optimized model\n",
    "pickle.dump(etr_cv_model, open(os.path.join(\n",
    "    MODELS_PATH, 'etr7_hyperparameters_tuned.pickle'), 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished fitting model, total time: 45.19 s\n",
      "dict_keys(['fit_time', 'score_time', 'test_r2', 'train_r2', 'test_rmse', 'train_rmse'])\n"
     ]
    }
   ],
   "source": [
    "# New XGBoost model after hyperparameter tuning\n",
    "xgb.set_config(verbosity=1)\n",
    "\n",
    "xgb_cv_model = XGBRegressor(learning_rate=0.1, max_depth=6,\n",
    "                            subsample=0.8, colsample_bytree=1.0, min_child_weight=5)\n",
    "\n",
    "scoring = {'r2': 'r2', 'rmse': 'neg_root_mean_squared_error'}\n",
    "\n",
    "ti = time()\n",
    "\n",
    "scores = cross_validate(xgb_cv_model, X_train_new, y_train_new, groups=groups,\n",
    "                        verbose=0, scoring=scoring, cv=gkf, return_train_score=True, error_score='raise')\n",
    "\n",
    "xgb_cv_model.fit(X_train_new, y_train_new, verbose=True)\n",
    "\n",
    "dt = time() - ti\n",
    "\n",
    "print(f'Finished fitting model, total time: {dt:0.2f} s')\n",
    "\n",
    "print(scores.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation R-squared scores: [0.86703962 0.88714957 0.80340339 0.88239111 0.85485597]\n",
      "Mean R-squared score: 0.858967933926485\n",
      "Cross-validation RMSE scores: [3.4139892  2.853421   4.43875718 3.28136419 3.57825711]\n",
      "Mean RMSE score: 3.5131577342202176\n"
     ]
    }
   ],
   "source": [
    "# Print cross-validation scores\n",
    "print(\"Cross-validation R-squared scores:\", scores['test_r2'])\n",
    "print(\"Mean R-squared score:\", scores['test_r2'].mean())\n",
    "\n",
    "# Negated because it's returned as a negative value\n",
    "print(\"Cross-validation RMSE scores:\", -scores['test_rmse'])\n",
    "print(\"Mean RMSE score:\", -scores['test_rmse'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.8477\n",
      "Root Mean Squared Error: 3.5607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrew/Desktop/School/Research/ChemML/env/lib/python3.10/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have a separate test set\n",
    "y_pred = xgb_cv_model.predict(X_test)\n",
    "\n",
    "# Calculate R-squared\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"R-squared: {r2:.4f}\")\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(f\"Root Mean Squared Error: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting most important features\n",
    "pio.renderers.default = 'browser'\n",
    "\n",
    "\n",
    "importances_list = etr_cv_model.feature_importances_.tolist()\n",
    "features_list = X_train_unscaled.columns.values.tolist()\n",
    "featureimportances_dict = dict(zip(features_list, importances_list))\n",
    "sorted_featureimportances_tuple = sorted(\n",
    "    featureimportances_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "sorted_featureimportances_dict = {\n",
    "    key: value for key, value in sorted_featureimportances_tuple}\n",
    "sorted_featureimportances_df = pd.DataFrame.from_dict(\n",
    "    [sorted_featureimportances_dict]).T\n",
    "sorted_featureimportances_df['Feature'] = sorted_featureimportances_df.index\n",
    "sorted_featureimportances_df.columns = ['Importance', 'Feature']\n",
    "\n",
    "\n",
    "sorted_featureimportances_df.to_csv(os.path.join(RESULTS_PATH, 'jarvis', 'Set7',\n",
    "                                                 'jarvis_feature_importance_table.csv'), index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the most important x features\n",
    "importances = etr_cv_model.feature_importances_\n",
    "included = X_train_unscaled.columns.values\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "fig_bar1 = px.bar(\n",
    "    x=included[indices][0:20],\n",
    "    y=importances[indices][0:20],\n",
    "    title=\"Feature importances of model\",\n",
    "    labels={\"x\": \"Feature\", \"y\": \"Importance\"}\n",
    ")\n",
    "\n",
    "\n",
    "# fig_bar.show()\n",
    "plotly.offline.plot(\n",
    "    fig_bar1, filename=os.path.join(ASSETS_PATH, 'jarvis', 'Set7',\n",
    "             'jarvis_top_features1.html')\n",
    "\n",
    "# plotting the least important features\n",
    "fig_bar2 = px.bar(\n",
    "    x=included[indices][-20:],\n",
    "    y=importances[indices][-20:],\n",
    "    title=\"Least important features of model\",\n",
    "    labels={\"x\": \"Feature\", \"y\": \"Importance\"}\n",
    ")\n",
    "plotly.offline.plot(\n",
    "    fig_bar2, filename=os.path.join(ASSETS_PATH, 'jarvis', 'Set7',\n",
    "             'jarvis_bottom_features1.html'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use RFECV to determine the optimal number of features\n",
    "etr_estimator = ExtraTreesRegressor(n_estimators=50, criterion='squared_error',\n",
    "                                    min_samples_split=10, min_samples_leaf=5, max_features=1.0)\n",
    "\n",
    "rfecv = RFECV(estimator=etr_estimator, step=0.01, cv=gkf, scoring='neg_mean_squared_error',\n",
    "              min_features_to_select=80, verbose=3)\n",
    "\n",
    "fit = rfecv.fit(X_train_new, y_train_new, groups=groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting performance vs number of features:\n",
    "\n",
    "print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
    "\n",
    "n_scores = len(rfecv.cv_results_['mean_test_score'])\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel('Mean test neg MSE')\n",
    "plt.errorbar(\n",
    "    range(5, n_scores + 5),\n",
    "    rfecv.cv_results_['mean_test_score'],\n",
    "    yerr=rfecv.cv_results_['std_test_score']\n",
    ")\n",
    "plt.title(\"Recursive Feature Elimination \\nwith correlated features\")\n",
    "\n",
    "rfecv_plot = plt.gcf()\n",
    "rfecv_plot.savefig(os.path.join(ASSETS_PATH, 'jarvis', 'Set7',\n",
    "                                'tunedModel_rfecv_plot_transparent.png'),\n",
    "                   bbox_inches='tight', dpi=600, transparent=True)\n",
    "rfecv_plot.savefig(os.path.join(ASSETS_PATH, 'jarvis', 'Set7',\n",
    "                                'tunedModel_rfecv_plot_.png'),\n",
    "                   bbox_inches='tight', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obsolete\n",
    "df_features_rfecv = pd.DataFrame(columns=['feature', 'support', 'ranking'])\n",
    "for i in range(X_train_new.shape[1]):\n",
    "    row = {'feature': i, 'support': rfecv.support_[\n",
    "        i], 'ranking': rfecv.ranking_[i]}\n",
    "    df_features_rfecv = df_features_rfecv.append(row, ignore_index=True)\n",
    "\n",
    "df_features_rfecv[df_features_rfecv['support'] == True]\n",
    "\n",
    "selected_features = rfecv.get_support(1)\n",
    "X_train_rfecv = df[df.columns[selected_features]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use recursive feature selection class in Sklearn to cut down the number of features.\n",
    "etr_estimator = ExtraTreesRegressor(n_estimators=100, criterion='squared_error',\n",
    "                                    min_samples_split=10, min_samples_leaf=6, max_features=1.0)\n",
    "\n",
    "# define the method\n",
    "rfe = RFE(estimator=etr_estimator,\n",
    "          n_features_to_select=91, step=0.01, verbose=4)\n",
    "\n",
    "# fit the model\n",
    "rfe.fit(X_train_new, y_train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try cutting down to 11:1 observations:features ratio\n",
    "\n",
    "# Make a new df with train and val and then featurize it.\n",
    "\n",
    "df_train_trim = pd.concat([df_train, df_val], ignore_index=True)\n",
    "\n",
    "# Get the bottom i features and remove them from the the train/val/test dataset\n",
    "i = 1615\n",
    "dropped_features = sorted_featureimportances_df['Feature'].tail(\n",
    "    i).values.tolist()\n",
    "df_dropped_features = pd.DataFrame(dropped_features)\n",
    "df_dropped_features.to_csv(os.path.join(RESULTS_PATH, 'jarvis', 'Set7',\n",
    "                                        'dropped_features.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train_trim_unscaled, y_train_trim, formulae_train_new, skipped_train_new = composition.generate_features(\n",
    "    df_train_trim, elem_prop='magpie', drop_duplicates=False, extend_features=True, sum_feat=True)\n",
    "\n",
    "X_train_trim_unscaled = X_train_trim_unscaled.drop(\n",
    "    axis=1, labels=dropped_features)\n",
    "\n",
    "columns_trim = X_train_trim_unscaled.columns.values.tolist()\n",
    "df_kept_columns = pd.DataFrame(columns_trim)\n",
    "df_kept_columns.to_csv(os.path.join(RESULTS_PATH, 'jarvis', 'Set7',\n",
    "                                    'kept_features.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_trim = scaler.fit_transform(X_train_trim_unscaled)\n",
    "\n",
    "X_train_trim = normalize(X_train_trim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check model CV performance with previous hyperparameters from all 1700+ features\n",
    "\n",
    "etr_cv_model2 = ExtraTreesRegressor(n_estimators=1000, criterion='squared_error',\n",
    "                                    min_samples_split=10, min_samples_leaf=5, max_features=1.0, verbose=4)\n",
    "\n",
    "scoring = {'r2': 'r2',\n",
    "           'rmse': 'neg_root_mean_squared_error'}\n",
    "\n",
    "ti = time()\n",
    "\n",
    "scores = cross_validate(etr_cv_model2, X_train_trim, y_train_trim, groups=groups, verbose=4,\n",
    "                        scoring=scoring, cv=gkf, return_train_score=True)\n",
    "\n",
    "etr_cv_model2.fit(X_train_trim, y_train_trim)\n",
    "dt = time() - ti\n",
    "\n",
    "print(f'Finished fitting model, total time: {dt:0.2f} s')\n",
    "\n",
    "pickle.dump(etr_cv_model2, open(os.path.join(\n",
    "    MODELS_PATH, 'etr7_trimmed_hyperparameters_tuned.pickle'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scores.keys())\n",
    "TRIMMED_train_scores = pd.DataFrame()\n",
    "TRIMMED_train_scores['test_r2'] = scores['test_r2']\n",
    "TRIMMED_train_scores['test_rmse'] = scores['test_rmse']\n",
    "UNTRIMMED_train_scores.to_csv(os.path.join(\n",
    "    RESULTS_PATH, 'jarvis', 'TRIMMED_test_rawData.csv'), index=False)\n",
    "\n",
    "scores_mean = {'r2': np.mean(scores['test_r2']),\n",
    "               'rmse': np.mean(scores['test_rmse'])}\n",
    "\n",
    "test_r2 = {'0': scores['test_r2'][0], '1': scores['test_r2'][1], '2': scores['test_r2'][2],\n",
    "           '3': scores['test_r2'][3], '4': scores['test_r2'][4]}\n",
    "\n",
    "plt.rcParams.update({'font.size': 25})\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(range(len(test_r2.keys())),\n",
    "         test_r2.values(), linestyle='-', marker='o')\n",
    "plt.xticks(range(len(test_r2)), [str(key) for key in list(test_r2.keys())])\n",
    "plt.ylim(0.7, 1)\n",
    "plt.text(0, .75, 'mean $r^2$ = {:0.3f}'.format(scores_mean['r2']), fontsize=25,\n",
    "         bbox=dict(facecolor='red', alpha=0.3))\n",
    "\n",
    "plt.xlabel('Cross validation folds')\n",
    "plt.ylabel('$r^2$')\n",
    "plt.title('$r^2$ across cross validation folds')\n",
    "\n",
    "r2_cv = plt.gcf()\n",
    "r2_cv.savefig(os.path.join(ASSETS_PATH, 'jarvis', 'Set7',\n",
    "                           'tunedModel2_TRIMMED_r2_5-fold_cv_{}_transparent.png'),\n",
    "              bbox_inches='tight', dpi=600, transparent=True)\n",
    "r2_cv.savefig(os.path.join(ASSETS_PATH, 'jarvis', 'Set7',\n",
    "                           'tunedModel2_TRIMMED_r2_5-fold_cv_{}_.png'),\n",
    "              bbox_inches='tight', dpi=600)\n",
    "\n",
    "\n",
    "test_rmse = {'0': np.negative(scores['test_rmse'][0]), '1': np.negative(scores['test_rmse'])[1],\n",
    "             '2': np.negative(scores['test_rmse'][2]), '3': np.negative(scores['test_rmse'][3]),\n",
    "             '4': np.negative(scores['test_rmse'])[4]}\n",
    "\n",
    "plt.rcParams.update({'font.size': 25})\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(range(len(test_rmse.keys())), test_rmse.values(),\n",
    "         linestyle='-', marker='o', color='green')\n",
    "plt.xticks(range(len(test_rmse)), [str(key) for key in list(test_rmse.keys())])\n",
    "plt.ylim(1, 5)\n",
    "plt.text(0.2, 2, 'mean RMSE = {:0.3f}'.format(np.negative(scores_mean['rmse'])), fontsize=25,\n",
    "         bbox=dict(facecolor='red', alpha=0.3))\n",
    "\n",
    "plt.xlabel('Cross validation folds')\n",
    "plt.ylabel('RMSE ($\\u03bc_B$/ f.u.)')\n",
    "plt.title('RMSE across cross validation folds')\n",
    "\n",
    "rmse_cv = plt.gcf()\n",
    "rmse_cv.savefig(os.path.join(ASSETS_PATH, 'jarvis', 'Set7',\n",
    "                             'tunedModel2_TRIMMED_rmse_5-fold_cv_{}_transparent.png'),\n",
    "                bbox_inches='tight', dpi=600, transparent=True)\n",
    "rmse_cv.savefig(os.path.join(ASSETS_PATH, 'jarvis', 'Set7',\n",
    "                             'tunedModel2_TRIMMED_rmse_5-fold_cv_{}_.png'),\n",
    "                bbox_inches='tight', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up hyperparameter tuning for TRIMMED model\n",
    "scoring = {'r2': 'r2',\n",
    "           'rmse': 'neg_root_mean_squared_error'}\n",
    "\n",
    "# Try with n_estimators = 50 to reduce computational cost and the change it to 1000 in next gs step\n",
    "params_etr = {'n_estimators': [50], 'min_samples_leaf': [\n",
    "    5, 6, 7, 8, 9, 10, 11, 12], 'min_samples_split': [5, 10, 15, 20, 30, 40], }\n",
    "\n",
    "\n",
    "ti = time()\n",
    "etr_model2_tune = ExtraTreesRegressor(\n",
    "    criterion='squared_error', random_state=RNG_SEED)\n",
    "gs_etr = GridSearchCV(estimator=etr_model2_tune, param_grid=params_etr, verbose=4,\n",
    "                      scoring='neg_root_mean_squared_error', cv=gkf, return_train_score=True, refit=True)\n",
    "\n",
    "dt = time() - ti\n",
    "print(f'Finished grid search, total time: {dt:0.2f} s')\n",
    "\n",
    "\n",
    "ti = time()\n",
    "gs_etr.fit(X_train_trim, y_train_trim, groups=groups)\n",
    "dt = time() - ti\n",
    "\n",
    "print(f'Finished fitting grid search model, total time: {dt:0.2f} s')\n",
    "\n",
    "# Convert results into a DataFrame\n",
    "gs2_results1 = pd.DataFrame(gs_etr.cv_results_)[\n",
    "    ['params', 'mean_test_score', 'mean_train_score', 'rank_test_score', 'mean_train_score']]\n",
    "# sort by test scores\n",
    "gs2_results1.sort_values('rank_test_score')\n",
    "\n",
    "mean_rmse_score = np.negative(gs_etr.best_score_)\n",
    "\n",
    "gs2_results1.to_csv(os.path.join(RESULTS_PATH, 'jarvis', 'Set7',\n",
    "                                 'gs2_results1.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Curve for TRIMMED model\n",
    "train_sizes = np.linspace(0.1, 1.0, 10)\n",
    "\n",
    "etr_model2 = ExtraTreesRegressor(n_estimators=1000, criterion='squared_error',\n",
    "                                 min_samples_split=10, min_samples_leaf=5, max_features=1.0, verbose=4)\n",
    "\n",
    "\n",
    "ti = time()\n",
    "train_sizes, train_scores, validation_scores = learning_curve(etr_model2, X_train_trim, y_train_trim,\n",
    "                                                              groups=groups, scoring='r2',\n",
    "                                                              cv=gkf,\n",
    "                                                              shuffle=True, random_state=RNG_SEED)\n",
    "dt = time() - ti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting learning curve\n",
    "\n",
    "train_scores_mean = train_scores.mean(axis=1)\n",
    "train_scores_std = train_scores.std(axis=1)\n",
    "\n",
    "TRIMMED_learn_curve_scores = pd.DataFrame()\n",
    "\n",
    "TRIMMED_learn_curve_scores['train_sizes'] = train_sizes\n",
    "TRIMMED_learn_curve_scores['train_r2'] = train_scores.mean(axis=1)\n",
    "TRIMMED_learn_curve_scores['validaton_r2'] = validation_scores.mean(axis=1)\n",
    "TRIMMED_learn_curve_scores.to_csv(os.path.join(RESULTS_PATH, 'jarvis', 'Set7',\n",
    "                                               'TRIMMED_learnCurve_rawData.csv'), index=False)\n",
    "\n",
    "\n",
    "val_scores_mean = validation_scores.mean(axis=1)\n",
    "val_scores_std = validation_scores.std(axis=1)\n",
    "print('Mean training scores\\n\\n', pd.Series(\n",
    "    train_scores_mean, index=train_sizes))\n",
    "print('\\n', '-' * 20)  # separator\n",
    "print('\\nMean validation scores\\n\\n', pd.Series(\n",
    "    val_scores_mean, index=train_sizes))\n",
    "\n",
    "\n",
    "plt.rcParams.update({'font.size': 25})\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(train_sizes, train_scores_mean, label='Training $r^2$')\n",
    "plt.plot(train_sizes, val_scores_mean, label='Validation $r^2$')\n",
    "plt.ylabel('r2 score', fontsize=25)\n",
    "plt.xlabel('Training set size', fontsize=25)\n",
    "plt.title('Learning curves for a linear regression model', fontsize=25, y=1.03)\n",
    "plt.legend()\n",
    "# plt.ylim(0,4)\n",
    "\n",
    "# plt.text(5.5,5,'gap = {:0.3f}'.format(np.negative.difference(train(validation_scores_mean[4])),\n",
    "#                                    train_scores_mean[4]), fontsize = 20,\n",
    "#         bbox = dict(facecolor = 'red', alpha = 0.3))\n",
    "\n",
    "\n",
    "learn_curve = plt.gcf()\n",
    "learn_curve.savefig(os.path.join(ASSETS_PATH, 'jarvis', 'Set7',\n",
    "                                 'learn_curve2_trimmed_transparent.png'),\n",
    "                    bbox_inches='tight', dpi=600, transparent=True)\n",
    "learn_curve.savefig(os.path.join(ASSETS_PATH, 'jarvis', 'Set7',\n",
    "                                 'learn_curve2_trimmed_.png'),\n",
    "                    bbox_inches='tight', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting most important features\n",
    "\n",
    "pio.renderers.default = 'browser'\n",
    "\n",
    "\n",
    "importances_list = etr_cv_model2.feature_importances_.tolist()\n",
    "features_list = X_train_trim_unscaled.columns.values.tolist()\n",
    "featureimportances_dict = dict(zip(features_list, importances_list))\n",
    "sorted_featureimportances_tuple = sorted(\n",
    "    featureimportances_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "sorted_featureimportances_dict = {\n",
    "    key: value for key, value in sorted_featureimportances_tuple}\n",
    "sorted_featureimportances_df = pd.DataFrame.from_dict(\n",
    "    [sorted_featureimportances_dict]).T\n",
    "sorted_featureimportances_df['Feature'] = sorted_featureimportances_df.index\n",
    "sorted_featureimportances_df.columns = ['Importance', 'Feature']\n",
    "\n",
    "sorted_featureimportances_df.to_csv(os.path.join(RESULTS_PATH, 'jarvis', 'Set7',\n",
    "                                                 'jarvis_TRIMMED_feature_importance_table.csv'), index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the most important x features\n",
    "importances = etr_cv_model2.feature_importances_\n",
    "included = X_train_trim_unscaled.columns.values\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "fig_bar1 = px.bar(\n",
    "    x=included[indices][0:20],\n",
    "    y=importances[indices][0:20],\n",
    "    title=\"Feature importances of model\",\n",
    "    labels={\"x\": \"Feature\", \"y\": \"Importance\"}\n",
    ")\n",
    "\n",
    "# fig_bar.show()\n",
    "plotly.offline.plot(\n",
    "    fig_bar1, filename=os.path.join(ASSETS_PATH, 'jarvis', 'Set7',\n",
    "                                    'jarvis_TRIMMED_top_features1.html'))\n",
    "\n",
    "# plotting the least important features\n",
    "fig_bar2 = px.bar(\n",
    "    x=included[indices][-20:],\n",
    "    y=importances[indices][-20:],\n",
    "    title=\"Least important features of model\",\n",
    "    labels={\"x\": \"Feature\", \"y\": \"Importance\"}\n",
    ")\n",
    "plotly.offline.plot(\n",
    "    fig_bar2, filename=ASSETS_PATH + '/jarvis/Set7/jarvis_TRIMMED_bottom_features1.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
